# -*- coding: utf-8 -*-
"""pyspark_randomforest.ipynb

Automatically generated by Colab.
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.functions import col
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import ClusteringEvaluator
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.feature import Imputer
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator

spark = SparkSession.builder.appName("mlbuilder").getOrCreate()

training_data = spark.read.csv('cs-training.csv',header=True,inferSchema=True)
test_data = spark.read.csv('cs-test.csv',header=True,inferSchema=True)

training_data = training_data.drop('Unnamed: 0')
test_data = test_data.drop('Unnamed: 0')

test_data.printSchema()

string_to_number = ['MonthlyIncome','NumberOfDependents']

for col_name in string_to_number:
    training_data = training_data.withColumn(col_name,col(col_name).cast('int'))
    test_data = test_data.withColumn(col_name,col(col_name).cast('int'))

imputer = Imputer(inputCols=['MonthlyIncome', 'NumberOfDependents'], outputCols=['MonthlyIncome', 'NumberOfDependents'])
training_data = imputer.fit(training_data).transform(training_data)
test_data = imputer.fit(test_data).transform(test_data)

training_data.show()

minority_class = training_data.filter(training_data.SeriousDlqin2yrs == 1)
majority_class = training_data.filter(training_data.SeriousDlqin2yrs == 0)

print('minority:',minority_class.count(),'majority:',majority_class.count())

majority_class_downsampled = majority_class.sample(withReplacement=False, fraction=float(minority_class.count()) / float(majority_class.count()))

balanced_training_data = minority_class.union(majority_class_downsampled)

balanced_training_data.printSchema()

features_columns = ['RevolvingUtilizationOfUnsecuredLines','age','NumberOfTime30-59DaysPastDueNotWorse','DebtRatio','MonthlyIncome','NumberOfOpenCreditLinesAndLoans',
                    'NumberOfTimes90DaysLate','NumberRealEstateLoansOrLines','NumberOfTime60-89DaysPastDueNotWorse','NumberOfDependents']

asserter = VectorAssembler(inputCols=features_columns,outputCol='features',handleInvalid='skip')

balanced_training_data= asserter.transform(balanced_training_data)

balanced_training_data.printSchema()

test = asserter.transform(test_data)

selected_train = balanced_training_data.select('features','SeriousDlqin2yrs')
selected_test = selected_train.select('features','SeriousDlqin2yrs')

rf = RandomForestClassifier(labelCol='SeriousDlqin2yrs',featuresCol='features',numTrees=100,maxDepth=7)

model = rf.fit(selected_train)

predictions = model.transform(selected_test)

predictions.show()

train_prediction = model.transform(selected_train)

def evaluate_model(predicts):
    evaluators = BinaryClassificationEvaluator(labelCol="SeriousDlqin2yrs", rawPredictionCol="prediction",metricName="areaUnderROC")
    accuracy = evaluators.evaluate(predicts)

    confusion_matrix = predicts.groupBy('SeriousDlqin2yrs', 'prediction').count()
    confusion_matrix.show()

    tp = confusion_matrix.filter((col('SeriousDlqin2yrs') == 1) & (col('prediction') == 1)).select('count').collect()[0][0]
    fp = confusion_matrix.filter((col('SeriousDlqin2yrs') == 0) & (col('prediction') == 1)).select('count').collect()[0][0]
    tn = confusion_matrix.filter((col('SeriousDlqin2yrs') == 0) & (col('prediction') == 0)).select('count').collect()[0][0]
    fn = confusion_matrix.filter((col('SeriousDlqin2yrs') == 1) & (col('prediction') == 0)).select('count').collect()[0][0]

    precision = tp / (tp + fp)
    recall = tp / (tp + fn)
    f1_score = 2 * (precision * recall) / (precision + recall)

    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1-Score: {f1_score}")

evaluate_model(predictions)

evaluate_model(train_prediction)

paramGrid = ParamGridBuilder() \
    .addGrid(rf.numTrees, [50, 100]) \
    .addGrid(rf.maxDepth, [5, 10]) \
    .build()

evaluator = BinaryClassificationEvaluator(labelCol="SeriousDlqin2yrs", rawPredictionCol="prediction", metricName="areaUnderROC")

crossval = CrossValidator(estimator=rf,
                          estimatorParamMaps=paramGrid,
                          evaluator=evaluator,
                          numFolds=10)

cvModel = crossval.fit(selected_train)

trainCV_predictions = cvModel.transform(balanced_training_data)
testCV_predictions = cvModel.transform(selected_test)

print('Train data performance:')
evaluate_model(trainCV_predictions)

print('Test data performance:')
evaluate_model(testCV_predictions)

bestModel = cvModel.bestModel
print("Best Param (numTrees): ", bestModel.getOrDefault("numTrees"))
print("Best Param (maxDepth): ", bestModel.getOrDefault("maxDepth"))
